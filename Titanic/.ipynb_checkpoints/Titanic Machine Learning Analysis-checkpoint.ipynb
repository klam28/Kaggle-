{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kerrylam/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import train_test_split \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn import svm\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline\n",
    "style.use(\"ggplot\")\n",
    "accuracy = metrics.accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m1 = rforest = RandomForestClassifier()\n",
    "m2 = logreg = LogisticRegression()\n",
    "m3 = knn = KNeighborsClassifier()\n",
    "m4 = gnb = GaussianNB()\n",
    "m5 = multi = MultinomialNB()\n",
    "m6 = bernoulli = BernoulliNB()\n",
    "\n",
    "m7 = poly = svm.SVC(kernel='poly', C=1,gamma='auto')\n",
    "m8 = rbf = svm.SVC(kernel='rbf', C=1,gamma='auto')\n",
    "m9 = linear = svm.SVC(kernel='linear', C=1,gamma='auto')\n",
    "m10 = sigmoid = svm.SVC(kernel='sigmoid', C=1,gamma='auto')\n",
    "\n",
    "models = [m1,m2,m3,m4,m5,m6]\n",
    "svm_models = [m7,m8,m9,m10] # Looping Through These SVM Models Lag The Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1309, 12)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"titanic_training.csv\", header = 0) \n",
    "test = pd.read_csv(\"titanic_test.csv\", header = 0)\n",
    "ID = test['PassengerId'] # Extract ID Names From Test Set\n",
    "data = pd.concat([train, test], axis = 0)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del data['Name'], data['Ticket'], data['Cabin'], data['PassengerId']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Manually Transforming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def transform_category(category): # Convert each string to a categorical value\n",
    "#     if category == 'Q': return 0\n",
    "#     if category == 'S': return 1\n",
    "#     if category == 'C': return 2\n",
    "\n",
    "# data['Embarked'] = data['Embarked'].apply(transform_category)\n",
    "\n",
    "# data.drop(data.index[data[\"Embarked\"] == 0])\n",
    "# data['Embarked'] = pd.get_dummies(data['Embarked'])\n",
    "# data['Sex'] = pd.get_dummies(data['Sex'])\n",
    "# # data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transforming Using a Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data['Sex'] = data.Sex.map({'male':1, 'female':0})\n",
    "# data['Embarked'] = data.Embarked.map({'Q':0, 'S':1, 'C':2})\n",
    "# data.drop(data.index[data[\"Embarked\"] == 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pandas Get Dummies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S    914\n",
      "C    270\n",
      "Q    123\n",
      "0      2\n",
      "Name: Embarked, dtype: int64 \n",
      "\n",
      "male      843\n",
      "female    466\n",
      "Name: Sex, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.Embarked.value_counts(), \"\\n\")\n",
    "print(data.Sex.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### pd.get_dummies and drop_first\n",
    "- Drops One Category to Avoid Collinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age     Fare  Parch  Pclass  SibSp  Survived  Sex_male  Embarked_C  \\\n",
       "0  22.0   7.2500      0       3      1       0.0         1           0   \n",
       "1  38.0  71.2833      0       1      1       1.0         0           1   \n",
       "2  26.0   7.9250      0       3      0       1.0         0           0   \n",
       "3  35.0  53.1000      0       1      1       1.0         0           0   \n",
       "4  35.0   8.0500      0       3      0       0.0         1           0   \n",
       "\n",
       "   Embarked_Q  Embarked_S  \n",
       "0           0           1  \n",
       "1           0           0  \n",
       "2           0           1  \n",
       "3           0           1  \n",
       "4           0           1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.get_dummies(data, columns = ['Sex', 'Embarked'], drop_first = True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age     Fare  Parch  Pclass  SibSp  Survived  Sex_male  Embarked_Q  \\\n",
       "0  22.0   7.2500      0       3      1       0.0         1           0   \n",
       "1  38.0  71.2833      0       1      1       1.0         0           0   \n",
       "2  26.0   7.9250      0       3      0       1.0         0           0   \n",
       "3  35.0  53.1000      0       1      1       1.0         0           0   \n",
       "4  35.0   8.0500      0       3      0       0.0         1           0   \n",
       "\n",
       "   Embarked_S  \n",
       "0           1  \n",
       "1           0  \n",
       "2           1  \n",
       "3           1  \n",
       "4           1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del data[\"Embarked_C\"]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# le = preprocessing.LabelEncoder()\n",
    "# le.fit(np.array(data.Embarked))\n",
    "# data[\"Embarked\"] = le.transform(data.Embarked)\n",
    "# le.fit(np.array(data.Sex))\n",
    "# data[\"Sex\"] = le.transform(data.Sex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Impute Missing Data | Split Data | Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.fillna(method = 'ffill', inplace = True) # Impute Missing Data\n",
    "data = data.astype(float) # Convert DF Type to Float\n",
    "\n",
    "\"\"\"Split Data\"\"\"\n",
    "train = data[0:len(train)]\n",
    "test = data[len(train):]\n",
    "\n",
    "\"\"\"Normalize Data for Faster Computation\"\"\"\n",
    "train = train/train.max().astype(np.float64)\n",
    "test = test/test.max().astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 9)\n",
      "(418, 9)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate Target From Training Data | Delete Survived Column From Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Data: (891, 9)\n",
      "Index Location of Target: 5\n"
     ]
    }
   ],
   "source": [
    "# Grab Location of Survived\n",
    "print(\"Shape of Data:\", train.shape)\n",
    "print(\"Index Location of Target:\", train.columns.get_loc(\"Survived\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target = train.ix[:,5] # Separate Target\n",
    "# X = pd.DataFrame(train.ix[:, 0:7]) # Join All Other Data\n",
    "\n",
    "X = pd.DataFrame.join(train.ix[:, :5], train.ix[:, 6:]) # Used If Target is Between Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Delete Target From Testing Set to Match Shape of Training Set\"\"\"\n",
    "del test['Survived'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891,)\n",
      "(891, 8)\n",
      "(418, 8)\n"
     ]
    }
   ],
   "source": [
    "print(target.shape)\n",
    "print(X.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data to Test Accuracy on Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features For Training Set:  (579, 8)\n",
      "Target Training Set:  (579,)\n",
      "Features For Testing Set:  (312, 8)\n",
      "Target For Testing Set:  (312,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "X_train, X_test, target_train, target_test = train_test_split(X, target, test_size = 0.35, random_state = 1)\n",
    "\n",
    "print (\"Features For Training Set: \", X_train.shape)\n",
    "print (\"Target Training Set: \", target_train.shape)\n",
    "print (\"Features For Testing Set: \", X_test.shape)\n",
    "print (\"Target For Testing Set: \", target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation on Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False) \n",
      "\n",
      "CV Score: [ 0.79411765  0.81081081  0.80952381  0.8         0.75      ] \n",
      "\n",
      "Mean CV Score: 0.792890453479 \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.86      0.78      0.82       204\n",
      "        1.0       0.65      0.77      0.70       108\n",
      "\n",
      "avg / total       0.79      0.78      0.78       312\n",
      "\n",
      "____________________________________________________________________________________________ \n",
      "\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False) \n",
      "\n",
      "CV Score: [ 0.8         0.75        0.72916667  0.87096774  0.72093023] \n",
      "\n",
      "Mean CV Score: 0.774212928232 \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.84      0.77      0.81       201\n",
      "        1.0       0.64      0.74      0.69       111\n",
      "\n",
      "avg / total       0.77      0.76      0.76       312\n",
      "\n",
      "____________________________________________________________________________________________ \n",
      "\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform') \n",
      "\n",
      "CV Score: [ 0.83333333  0.8         0.79487179  0.73170732  0.71428571] \n",
      "\n",
      "Mean CV Score: 0.774839631913 \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.88      0.78      0.83       206\n",
      "        1.0       0.65      0.78      0.71       106\n",
      "\n",
      "avg / total       0.80      0.78      0.79       312\n",
      "\n",
      "____________________________________________________________________________________________ \n",
      "\n",
      "GaussianNB(priors=None) \n",
      "\n",
      "CV Score: [ 0.59090909  0.69090909  0.77777778  0.79310345  0.6875    ] \n",
      "\n",
      "Mean CV Score: 0.708039881574 \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.78      0.77      0.78       186\n",
      "        1.0       0.67      0.68      0.68       126\n",
      "\n",
      "avg / total       0.74      0.74      0.74       312\n",
      "\n",
      "____________________________________________________________________________________________ \n",
      "\n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True) \n",
      "\n",
      "CV Score: [ 0.75        0.6         0.66666667  0.83333333  0.46153846] \n",
      "\n",
      "Mean CV Score: 0.662307692308 \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      0.61      0.74       280\n",
      "        1.0       0.16      0.62      0.25        32\n",
      "\n",
      "avg / total       0.85      0.62      0.69       312\n",
      "\n",
      "____________________________________________________________________________________________ \n",
      "\n",
      "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True) \n",
      "\n",
      "CV Score: [ 0.77419355  0.73333333  0.7         0.83870968  0.68888889] \n",
      "\n",
      "Mean CV Score: 0.747025089606 \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.82      0.78      0.80       193\n",
      "        1.0       0.66      0.71      0.69       119\n",
      "\n",
      "avg / total       0.76      0.75      0.75       312\n",
      "\n",
      "____________________________________________________________________________________________ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    model.fit(X_train, target_train)\n",
    "    target_pred = model.predict(X_test)\n",
    "    cv_score = cross_val_score(model, X_train, target_train, cv=5, scoring = 'precision')\n",
    "    print(model, \"\\n\")\n",
    "    print(\"CV Score:\",cv_score, \"\\n\")\n",
    "    print('Mean CV Score:',np.mean(cv_score), \"\\n\")\n",
    "    print(metrics.classification_report(target_pred, target_test))\n",
    "    print(\"____________________________________________________________________________________________\", \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation on SVM Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='poly',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False) \n",
      "\n",
      "CV Score: [ 0.74285714  0.71153846  0.7         0.80555556  0.64705882] \n",
      "\n",
      "Mean CV Score: 0.721401996696 \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.72      0.79      0.75       167\n",
      "        1.0       0.73      0.64      0.68       145\n",
      "\n",
      "avg / total       0.72      0.72      0.72       312\n",
      "\n",
      "____________________________________________________________________________________________ \n",
      "\n",
      "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False) \n",
      "\n",
      "CV Score: [ 0.77419355  0.74418605  0.72916667  0.87096774  0.68888889] \n",
      "\n",
      "Mean CV Score: 0.761480578478 \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.83      0.78      0.80       196\n",
      "        1.0       0.66      0.72      0.69       116\n",
      "\n",
      "avg / total       0.76      0.76      0.76       312\n",
      "\n",
      "____________________________________________________________________________________________ \n",
      "\n",
      "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False) \n",
      "\n",
      "CV Score: [ 0.77419355  0.74418605  0.72916667  0.87096774  0.68888889] \n",
      "\n",
      "Mean CV Score: 0.761480578478 \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.83      0.78      0.80       196\n",
      "        1.0       0.66      0.72      0.69       116\n",
      "\n",
      "avg / total       0.76      0.76      0.76       312\n",
      "\n",
      "____________________________________________________________________________________________ \n",
      "\n",
      "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='sigmoid',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False) \n",
      "\n",
      "CV Score: [ 0.77419355  0.74418605  0.72916667  0.87096774  0.68888889] \n",
      "\n",
      "Mean CV Score: 0.761480578478 \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.83      0.78      0.80       196\n",
      "        1.0       0.66      0.72      0.69       116\n",
      "\n",
      "avg / total       0.76      0.76      0.76       312\n",
      "\n",
      "____________________________________________________________________________________________ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in svm_models:\n",
    "    model.fit(X_train, target_train)\n",
    "    target_pred = model.predict(X_test)\n",
    "    cv_score = cross_val_score(model, X_train, target_train, cv=5, scoring = 'precision')\n",
    "    print(model, \"\\n\")\n",
    "    print(\"CV Score:\",cv_score, \"\\n\")\n",
    "    print('Mean CV Score:',np.mean(cv_score), \"\\n\")\n",
    "    print(metrics.classification_report(target_pred, target_test))\n",
    "    print(\"____________________________________________________________________________________________\", \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Accuracy Look: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### SVM Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.12 % Accuracy\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='poly',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False) \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.72      0.79      0.75       167\n",
      "        1.0       0.73      0.64      0.68       145\n",
      "\n",
      "avg / total       0.72      0.72      0.72       312\n",
      " \n",
      "\n",
      "____________________________________________________________________________________________ \n",
      "\n",
      "75.64 % Accuracy\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False) \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.83      0.78      0.80       196\n",
      "        1.0       0.66      0.72      0.69       116\n",
      "\n",
      "avg / total       0.76      0.76      0.76       312\n",
      " \n",
      "\n",
      "____________________________________________________________________________________________ \n",
      "\n",
      "75.64 % Accuracy\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False) \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.83      0.78      0.80       196\n",
      "        1.0       0.66      0.72      0.69       116\n",
      "\n",
      "avg / total       0.76      0.76      0.76       312\n",
      " \n",
      "\n",
      "____________________________________________________________________________________________ \n",
      "\n",
      "75.64 % Accuracy\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='sigmoid',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False) \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.83      0.78      0.80       196\n",
      "        1.0       0.66      0.72      0.69       116\n",
      "\n",
      "avg / total       0.76      0.76      0.76       312\n",
      " \n",
      "\n",
      "____________________________________________________________________________________________ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_kernels = ['poly','rbf','linear','sigmoid']\n",
    "for i in svm_kernels:\n",
    "    mod = svm.SVC(kernel = i)\n",
    "    mod.fit(X_train, target_train)\n",
    "    target_pred = mod.predict(X_test)\n",
    "    print(round(accuracy(target_test, target_pred)*100, 2), \"% Accuracy\")\n",
    "    print(mod, \"\\n\")\n",
    "    print(metrics.classification_report(target_pred, target_test), \"\\n\")\n",
    "    print(\"____________________________________________________________________________________________\", \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### All Other Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78.21 % Accuracy\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False) \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.89      0.78      0.83       210\n",
      "        1.0       0.63      0.79      0.70       102\n",
      "\n",
      "avg / total       0.80      0.78      0.79       312\n",
      "\n",
      "____________________________________________________________________________________________ \n",
      "\n",
      "75.96 % Accuracy\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False) \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.84      0.77      0.81       201\n",
      "        1.0       0.64      0.74      0.69       111\n",
      "\n",
      "avg / total       0.77      0.76      0.76       312\n",
      "\n",
      "____________________________________________________________________________________________ \n",
      "\n",
      "78.21 % Accuracy\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform') \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.88      0.78      0.83       206\n",
      "        1.0       0.65      0.78      0.71       106\n",
      "\n",
      "avg / total       0.80      0.78      0.79       312\n",
      "\n",
      "____________________________________________________________________________________________ \n",
      "\n",
      "73.72 % Accuracy\n",
      "GaussianNB(priors=None) \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.78      0.77      0.78       186\n",
      "        1.0       0.67      0.68      0.68       126\n",
      "\n",
      "avg / total       0.74      0.74      0.74       312\n",
      "\n",
      "____________________________________________________________________________________________ \n",
      "\n",
      "61.54 % Accuracy\n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True) \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      0.61      0.74       280\n",
      "        1.0       0.16      0.62      0.25        32\n",
      "\n",
      "avg / total       0.85      0.62      0.69       312\n",
      "\n",
      "____________________________________________________________________________________________ \n",
      "\n",
      "75.32 % Accuracy\n",
      "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True) \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.82      0.78      0.80       193\n",
      "        1.0       0.66      0.71      0.69       119\n",
      "\n",
      "avg / total       0.76      0.75      0.75       312\n",
      "\n",
      "____________________________________________________________________________________________ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in models: \n",
    "    model.fit(X_train, target_train)\n",
    "    target_pred = model.predict(X_test)\n",
    "    print(round(accuracy(target_test, target_pred)*100, 2), \"% Accuracy\")\n",
    "    print(model, \"\\n\")\n",
    "    print(metrics.classification_report(target_pred, target_test))\n",
    "    print(\"____________________________________________________________________________________________\", \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interact SVM Models to Test Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.32 % Accuracy\n",
      "SVC(C=50, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=50, gamma=50, kernel='poly',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False) \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.82      0.78      0.80       193\n",
      "        1.0       0.66      0.71      0.69       119\n",
      "\n",
      "avg / total       0.76      0.75      0.75       312\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"SVM Model: poly\"\"\"\n",
    "from ipywidgets import interact\n",
    "\"\"\"Specify Ranges\"\"\"\n",
    "ranges = [1,100,1]\n",
    "\"\"\"Create Interact Bars For Adjusting Parameters\"\"\"\n",
    "\"\"\"Create Function That Takes the Interact Arguments\"\"\"\n",
    "@interact(c_range = ranges, degree = ranges, gamma = ranges)\n",
    "def acc1(c_range, degree, gamma):\n",
    "    \"\"\"Set Model and Parameters\"\"\"\n",
    "    model = svm.SVC(kernel = 'poly', C = c_range, degree = degree, gamma = gamma)\n",
    "    \"\"\"Fit Data\"\"\"\n",
    "    model.fit(X_train, target_train)\n",
    "    \"\"\"Print Accuracy\"\"\"\n",
    "    print(round(accuracy(target_test, target_pred)*100, 2), \"% Accuracy\")\n",
    "    \"\"\"Print Specifications of Model\"\"\"\n",
    "    print(model, \"\\n\")\n",
    "    \"\"\"Print Metrics\"\"\"\n",
    "    print(metrics.classification_report(target_pred, target_test), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.32 % Accuracy\n",
      "SVC(C=50, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=50, gamma=50, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False) \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.82      0.78      0.80       193\n",
      "        1.0       0.66      0.71      0.69       119\n",
      "\n",
      "avg / total       0.76      0.75      0.75       312\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"SVM Model: rbf\"\"\"\n",
    "from ipywidgets import interact\n",
    "ranges = [1,100,1]\n",
    "@interact(c_range = ranges, degree = ranges, gamma = ranges)\n",
    "def acc2(c_range, degree, gamma):\n",
    "    model = svm.SVC(kernel = 'rbf', C = c_range, degree = degree, gamma = gamma)\n",
    "    model.fit(X_train, target_train)\n",
    "    print(round(accuracy(target_test, target_pred)*100, 2), \"% Accuracy\")\n",
    "    print(model, \"\\n\")\n",
    "    print(metrics.classification_report(target_pred, target_test), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.32 % Accuracy\n",
      "SVC(C=50, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=50, gamma=50, kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False) \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.82      0.78      0.80       193\n",
      "        1.0       0.66      0.71      0.69       119\n",
      "\n",
      "avg / total       0.76      0.75      0.75       312\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"SVM Model: linear\"\"\"\n",
    "from ipywidgets import interact\n",
    "ranges = [1,100,1]\n",
    "@interact(c_range = ranges, degree = ranges, gamma = ranges)\n",
    "def acc3(c_range, degree, gamma):\n",
    "    model = svm.SVC(kernel = 'linear', C = c_range, degree = degree, gamma = gamma)\n",
    "    model.fit(X_train, target_train)\n",
    "    print(round(accuracy(target_test, target_pred)*100, 2), \"% Accuracy\")\n",
    "    print(model, \"\\n\")\n",
    "    print(metrics.classification_report(target_pred, target_test), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.32 % Accuracy\n",
      "SVC(C=50, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=50, gamma=50, kernel='sigmoid',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False) \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.82      0.78      0.80       193\n",
      "        1.0       0.66      0.71      0.69       119\n",
      "\n",
      "avg / total       0.76      0.75      0.75       312\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"SVM Model: sigmoid\"\"\"\n",
    "from ipywidgets import interact\n",
    "ranges = [1,100,1]\n",
    "@interact(c_range = ranges, degree = ranges, gamma = ranges)\n",
    "def acc4(c_range, degree, gamma):\n",
    "    model = svm.SVC(kernel = 'sigmoid', C = c_range, degree = degree, gamma = gamma)\n",
    "    model.fit(X_train, target_train)\n",
    "    print(round(accuracy(target_test, target_pred)*100, 2), \"% Accuracy\")\n",
    "    print(model, \"\\n\")\n",
    "    print(metrics.classification_report(target_pred, target_test), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.32 % Accuracy\n"
     ]
    }
   ],
   "source": [
    "\"\"\"K Nearest Neighbors\"\"\"\n",
    "from ipywidgets import interact\n",
    "@interact(neighbors = [1,100,1])\n",
    "def acc5(neighbors):\n",
    "    model = KNeighborsClassifier(n_neighbors = neighbors)\n",
    "    model.fit(X_train, target_train)\n",
    "    print(round(accuracy(target_test, target_pred)*100, 2), \"% Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.32 % Accuracy \n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=51,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=51, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Random Forest\"\"\"\n",
    "from ipywidgets import interact\n",
    "ranges = [2,100,1]\n",
    "@interact(n_estimators = ranges, min_samples_split = ranges)\n",
    "def acc5(n_estimators, min_samples_split):\n",
    "    model = RandomForestClassifier(n_estimators = n_estimators, min_samples_split = min_samples_split)\n",
    "    model.fit(X_train, target_train)\n",
    "    print(round(accuracy(target_test, target_pred)*100, 2), \"% Accuracy\", \"\\n\")\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Accuracy on a Single Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.68 % Accuracy\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False) \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.85      0.75      0.80       207\n",
      "        1.0       0.60      0.73      0.66       105\n",
      "\n",
      "avg / total       0.76      0.75      0.75       312\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = m1\n",
    "model.fit(X_train, target_train)\n",
    "target_pred = model.predict(X_test)\n",
    "print (round(accuracy(target_test, target_pred)*100, 2), \"% Accuracy\")\n",
    "print(model, \"\\n\")\n",
    "print(metrics.classification_report(target_pred, target_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNeighborsClassifier().get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.808080808081 \n",
      "\n",
      "{'n_neighbors': 12} \n",
      "\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=12, p=2,\n",
      "           weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Get Parameters of a Model Using: Model().get_params()\"\"\"\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\"\"\"Specify a Range\"\"\"\n",
    "ranges = range(1,50)\n",
    "\"\"\"Set a Model's Parameter to the Ranges to Try in GridSearch Using a Dictionary\"\"\"\n",
    "param_grid = dict(n_neighbors = ranges)\n",
    "\"\"\"Specify the Model\"\"\"\n",
    "Model = KNeighborsClassifier()\n",
    "\"\"\"Instantiate the GridSearchModel With Model, Parameter Grid, and Proper Parameters of Grid\"\"\"\n",
    "grid = GridSearchCV(Model, param_grid, cv = 10, scoring = 'accuracy')\n",
    "\"\"\"Fit Unsplit Data\"\"\"\n",
    "grid.fit(X, target)\n",
    "\"\"\"Output Scores\"\"\"\n",
    "grid.grid_scores_\n",
    "\n",
    "print(grid.best_score_, \"\\n\")\n",
    "print(grid.best_params_, \"\\n\")\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search On SVM Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.787878787879 \n",
      "\n",
      "{'C': 1, 'intercept_scaling': 2} \n",
      "\n",
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=2, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Logistic Regression\"\"\"\n",
    "ranges = range(1,30)\n",
    "param_grid = dict(C = ranges, intercept_scaling = ranges)\n",
    "Model = LogisticRegression()\n",
    "grid = GridSearchCV(Model, param_grid, cv = 10, scoring = \"accuracy\")\n",
    "grid.fit(X, target)\n",
    "grid.grid_scores_\n",
    "\n",
    "print(grid.best_score_, \"\\n\")\n",
    "print(grid.best_params_, \"\\n\")\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MultinomialNB().get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.643097643098 \n",
      "\n",
      "{'alpha': 0.0001} \n",
      "\n",
      "MultinomialNB(alpha=0.0001, class_prior=None, fit_prior=True)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"MultinomalNB\"\"\"\n",
    "ranges = (0.0001,0.001, 0.01, 1)\n",
    "param_grid = dict(alpha = ranges)\n",
    "Model = MultinomialNB()\n",
    "grid = GridSearchCV(Model, param_grid, cv = 10, scoring = 'accuracy')\n",
    "grid.fit(X, target)\n",
    "grid.grid_scores_\n",
    "\n",
    "print(grid.best_score_, \"\\n\")\n",
    "print(grid.best_params_, \"\\n\")\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.SVC().get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.786756453423 \n",
      "\n",
      "{'kernel': 'rbf'} \n",
      "\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Grid Search on Multiple SVM Models\"\"\"\n",
    "\n",
    "\"\"\"Specify a Range of Kernels to Try\"\"\"\n",
    "kernel_options = ['poly','rbf','linear','sigmoid']\n",
    "\"\"\"Specify a Range to Try\"\"\"\n",
    "ranges = range(1,15)\n",
    "\"\"\"Set a Model's Parameter to the Ranges to Try in GridSearch Using a Dictionary\"\"\"\n",
    "param_grid = dict(kernel = kernel_options)\n",
    "\"\"\"Specify the Model\"\"\"\n",
    "Model = svm.SVC()\n",
    "\"\"\"Instantiate the GridSearchModel With Model, Parameter Grid, and Proper Parameters of Grid\"\"\"\n",
    "grid = GridSearchCV(Model, param_grid, cv = 10, scoring = 'accuracy')\n",
    "\"\"\"Fit Unsplit Data\"\"\"\n",
    "grid.fit(X, target)\n",
    "\"\"\"Output Scores\"\"\"\n",
    "grid.grid_scores_\n",
    "\n",
    "print(grid.best_score_, \"\\n\")\n",
    "print(grid.best_params_, \"\\n\")\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.82379349046 \n",
      "\n",
      "{'C': 6, 'gamma': 2, 'kernel': 'rbf'} \n",
      "\n",
      "SVC(C=6, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=2, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Grid Search on Single SVM Model With Multiple Parameters\"\"\"\n",
    "kernel_options = ['rbf']\n",
    "\"\"\"Specify a Range to Try\"\"\"\n",
    "ranges = range(1,15)\n",
    "\"\"\"Set a Model's Parameter to the Ranges to Try in GridSearch Using a Dictionary\"\"\"\n",
    "param_grid = dict(kernel = kernel_options, C = ranges, gamma = ranges)\n",
    "\"\"\"Specify the Model\"\"\"\n",
    "Model = svm.SVC()\n",
    "\"\"\"Instantiate the GridSearchModel With Model, Parameter Grid, and Proper Parameters of Grid\"\"\"\n",
    "grid = GridSearchCV(Model, param_grid, cv = 10, scoring = 'accuracy')\n",
    "\"\"\"Fit Unsplit Data\"\"\"\n",
    "grid.fit(X, target)\n",
    "\"\"\"Output Scores\"\"\"\n",
    "grid.grid_scores_\n",
    "\n",
    "print(grid.best_score_, \"\\n\")\n",
    "print(grid.best_params_, \"\\n\")\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Search for Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "kernel_options = ['poly','rbf','linear','sigmoid']\n",
    "\"\"\"Specify a Range\"\"\"\n",
    "ranges = range(1,5)\n",
    "\"\"\"Set a Model's Parameter to the Ranges to Try in GridSearch Using a Dictionary\"\"\"\n",
    "param_rand = dict(kernel = kernel_options, C = ranges, gamma = ranges)\n",
    "\"\"\"Specify the Model\"\"\"\n",
    "Model2 = svm.SVC()\n",
    "\"\"\"Instantiate the RandomizedSearchModel With Model, Parameter Grid, Scoring, etc, and n_iter\"\"\"\n",
    "randsearch = RandomizedSearchCV(Model2, param_rand, cv = 10, scoring = 'accuracy', n_iter = 4)\n",
    "\"\"\"Fit Unsplit Data\"\"\"\n",
    "randsearch.fit(X, target)\n",
    "\"\"\"Output Scores\"\"\"\n",
    "randsearch.grid_scores_\n",
    "\n",
    "print(randsearch.best_score_, \"\\n\")\n",
    "print(randsearch.best_params_, \"\\n\")\n",
    "print(randsearch.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on Actual Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Note: Update Parameters For Better Accuracy\n",
    "estimator = m1\n",
    "y_pred = estimator.predict(test)\n",
    "predictions = pd.DataFrame(ID)\n",
    "def predict(predictions):\n",
    "    predictions[\"Survived\"] = y_pred\n",
    "    predictions = predictions.astype(int)\n",
    "    return predictions\n",
    "\n",
    "predict(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predictions.to_csv('titanic_submission.csv',index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "widgets": {
   "state": {
    "01c00f83d43b40ae96a87dd0629f14e0": {
     "views": [
      {
       "cell_index": 43
      }
     ]
    },
    "108b193181974a62a8b1a4007dac983b": {
     "views": [
      {
       "cell_index": 40
      }
     ]
    },
    "86d3923ae19a4f34b9d22e67a164f355": {
     "views": [
      {
       "cell_index": 42
      }
     ]
    },
    "c1ce8d4c20f047279c9f046fc3ab5941": {
     "views": [
      {
       "cell_index": 39
      }
     ]
    },
    "c5b698a1e7f24583a479d76aa12dde55": {
     "views": [
      {
       "cell_index": 44
      }
     ]
    },
    "fd0b190c80ff4b4b8c940f9cafd367a1": {
     "views": [
      {
       "cell_index": 41
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
