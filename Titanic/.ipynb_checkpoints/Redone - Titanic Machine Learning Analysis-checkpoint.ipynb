{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kerrylam/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import train_test_split \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "enc  = OneHotEncoder()\n",
    "from sklearn import preprocessing\n",
    "\n",
    "%matplotlib inline\n",
    "style.use(\"ggplot\")\n",
    "\n",
    "accuracy = metrics.accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m1 = rforest = RandomForestClassifier()\n",
    "m2 = logreg = LogisticRegression()\n",
    "m3 = knn = KNeighborsClassifier()\n",
    "m4 = gnb = GaussianNB()\n",
    "m5 = multi = MultinomialNB()\n",
    "m6 = bernoulli = BernoulliNB()\n",
    "\n",
    "m7 = poly = svm.SVC(kernel='poly', C=1,gamma='auto')\n",
    "m8 = rbf = svm.SVC(kernel='rbf', C=1,gamma='auto')\n",
    "m9 = linear = svm.SVC(kernel='linear', C=1,gamma='auto')\n",
    "m10 = sigmoid = svm.SVC(kernel='sigmoid', C=1,gamma='auto')\n",
    "\n",
    "models = [m1,m2,m3,m4,m5,m6]\n",
    "svm_models = [m7,m8,m9,m10] # Looping Through These SVM Models Lag The Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1309, 12)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"titanic_training.csv\", header = 0) \n",
    "test = pd.read_csv(\"titanic_test.csv\", header = 0)\n",
    "ID = test['PassengerId'] # Extract ID Names From Test Set\n",
    "data = pd.concat([train, test], axis = 0)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del data['Name'], data['Ticket'], data['Cabin'], data['PassengerId']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Manually Transforming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def transform_category(category): # Convert each string to a categorical value\n",
    "#     if category == 'Q': return 0\n",
    "#     if category == 'S': return 1\n",
    "#     if category == 'C': return 2\n",
    "\n",
    "# data['Embarked'] = data['Embarked'].apply(transform_category)\n",
    "\n",
    "# data.drop(data.index[data[\"Embarked\"] == 0])\n",
    "# data['Embarked'] = pd.get_dummies(data['Embarked'])\n",
    "# data['Sex'] = pd.get_dummies(data['Sex'])\n",
    "# # data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transforming Using a Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data['Sex'] = data.Sex.map({'male':1, 'female':0})\n",
    "# data['Embarked'] = data.Embarked.map({'Q':0, 'S':1, 'C':2})\n",
    "# data.drop(data.index[data[\"Embarked\"] == 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pandas Get Dummies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S    914\n",
      "C    270\n",
      "Q    123\n",
      "0      2\n",
      "Name: Embarked, dtype: int64 \n",
      "\n",
      "male      843\n",
      "female    466\n",
      "Name: Sex, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.Embarked.value_counts(), \"\\n\")\n",
    "print(data.Sex.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### pd.get_dummies and drop_first\n",
    "- Drops One Category to Avoid Collinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age     Fare  Parch  Pclass  SibSp  Survived  Sex_male  Embarked_C  \\\n",
       "0  22.0   7.2500      0       3      1       0.0         1           0   \n",
       "1  38.0  71.2833      0       1      1       1.0         0           1   \n",
       "2  26.0   7.9250      0       3      0       1.0         0           0   \n",
       "3  35.0  53.1000      0       1      1       1.0         0           0   \n",
       "4  35.0   8.0500      0       3      0       0.0         1           0   \n",
       "\n",
       "   Embarked_Q  Embarked_S  \n",
       "0           0           1  \n",
       "1           0           0  \n",
       "2           0           1  \n",
       "3           0           1  \n",
       "4           0           1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.get_dummies(data, columns = ['Sex', 'Embarked'], drop_first = True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age     Fare  Parch  Pclass  SibSp  Survived  Sex_male  Embarked_Q  \\\n",
       "0  22.0   7.2500      0       3      1       0.0         1           0   \n",
       "1  38.0  71.2833      0       1      1       1.0         0           0   \n",
       "2  26.0   7.9250      0       3      0       1.0         0           0   \n",
       "3  35.0  53.1000      0       1      1       1.0         0           0   \n",
       "4  35.0   8.0500      0       3      0       0.0         1           0   \n",
       "\n",
       "   Embarked_S  \n",
       "0           1  \n",
       "1           0  \n",
       "2           1  \n",
       "3           1  \n",
       "4           1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del data[\"Embarked_C\"]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# le = preprocessing.LabelEncoder()\n",
    "# le.fit(np.array(data.Embarked))\n",
    "# data[\"Embarked\"] = le.transform(data.Embarked)\n",
    "# le.fit(np.array(data.Sex))\n",
    "# data[\"Sex\"] = le.transform(data.Sex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Impute Missing Data | Split Data | Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.fillna(method = 'ffill', inplace = True) # Impute Missing Data\n",
    "data = data.astype(float) # Convert DF Type to Float\n",
    "\n",
    "\"\"\"Split Data\"\"\"\n",
    "train = data[0:len(train)]\n",
    "test = data[len(train):]\n",
    "\n",
    "\"\"\"Normalize Data for Faster Computation\"\"\"\n",
    "train = train/train.max().astype(np.float64)\n",
    "test = test/test.max().astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 9)\n",
      "(418, 9)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate Target From Training Data | Delete Survived Column From Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Data: (891, 9)\n",
      "Index Location of Target: 5\n"
     ]
    }
   ],
   "source": [
    "# Grab Location of Survived\n",
    "print(\"Shape of Data:\", train.shape)\n",
    "print(\"Index Location of Target:\", train.columns.get_loc(\"Survived\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target = train.ix[:,5] # Separate Target\n",
    "# X = pd.DataFrame(train.ix[:, 0:7]) # Join All Other Data\n",
    "\n",
    "X = pd.DataFrame.join(train.ix[:, :5], train.ix[:, 6:]) # Used If Target is Between Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Delete Target From Testing Set to Match Shape of Training Set\"\"\"\n",
    "del test['Survived'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891,)\n",
      "(891, 8)\n",
      "(418, 8)\n"
     ]
    }
   ],
   "source": [
    "print(target.shape)\n",
    "print(X.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data to Test Accuracy on Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features For Training Set:  (579, 8)\n",
      "Target Training Set:  (579,)\n",
      "Features For Testing Set:  (312, 8)\n",
      "Target For Testing Set:  (312,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "X_train, X_test, target_train, target_test = train_test_split(X, target, test_size = 0.35, random_state = 1)\n",
    "\n",
    "print (\"Features For Training Set: \", X_train.shape)\n",
    "print (\"Target Training Set: \", target_train.shape)\n",
    "print (\"Features For Testing Set: \", X_test.shape)\n",
    "print (\"Target For Testing Set: \", target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation on Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False) \n",
      "\n",
      "CV Score: [ 0.79487179  0.75609756  0.8125      0.79411765  0.78378378] \n",
      "\n",
      "Mean CV Score: 0.788274157338 \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.87      0.74      0.80       216\n",
      "        1.0       0.56      0.75      0.64        96\n",
      "\n",
      "avg / total       0.78      0.74      0.75       312\n",
      "\n",
      "____________________________________________________________________________________________ \n",
      "\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False) \n",
      "\n",
      "CV Score: [ 0.8         0.75        0.72916667  0.87096774  0.72093023] \n",
      "\n",
      "Mean CV Score: 0.774212928232 \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.84      0.77      0.81       201\n",
      "        1.0       0.64      0.74      0.69       111\n",
      "\n",
      "avg / total       0.77      0.76      0.76       312\n",
      "\n",
      "____________________________________________________________________________________________ \n",
      "\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform') \n",
      "\n",
      "CV Score: [ 0.83333333  0.8         0.79487179  0.73170732  0.71428571] \n",
      "\n",
      "Mean CV Score: 0.774839631913 \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.88      0.78      0.83       206\n",
      "        1.0       0.65      0.78      0.71       106\n",
      "\n",
      "avg / total       0.80      0.78      0.79       312\n",
      "\n",
      "____________________________________________________________________________________________ \n",
      "\n",
      "GaussianNB(priors=None) \n",
      "\n",
      "CV Score: [ 0.59090909  0.69090909  0.77777778  0.79310345  0.6875    ] \n",
      "\n",
      "Mean CV Score: 0.708039881574 \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.78      0.77      0.78       186\n",
      "        1.0       0.67      0.68      0.68       126\n",
      "\n",
      "avg / total       0.74      0.74      0.74       312\n",
      "\n",
      "____________________________________________________________________________________________ \n",
      "\n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True) \n",
      "\n",
      "CV Score: [ 0.75        0.6         0.66666667  0.83333333  0.46153846] \n",
      "\n",
      "Mean CV Score: 0.662307692308 \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      0.61      0.74       280\n",
      "        1.0       0.16      0.62      0.25        32\n",
      "\n",
      "avg / total       0.85      0.62      0.69       312\n",
      "\n",
      "____________________________________________________________________________________________ \n",
      "\n",
      "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True) \n",
      "\n",
      "CV Score: [ 0.77419355  0.73333333  0.7         0.83870968  0.68888889] \n",
      "\n",
      "Mean CV Score: 0.747025089606 \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.82      0.78      0.80       193\n",
      "        1.0       0.66      0.71      0.69       119\n",
      "\n",
      "avg / total       0.76      0.75      0.75       312\n",
      "\n",
      "____________________________________________________________________________________________ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    model.fit(X_train, target_train)\n",
    "    target_pred = model.predict(X_test)\n",
    "    cv_score = cross_val_score(model, X_train, target_train, cv=5, scoring = 'precision')\n",
    "    print(model, \"\\n\")\n",
    "    print(\"CV Score:\",cv_score, \"\\n\")\n",
    "    print('Mean CV Score:',np.mean(cv_score), \"\\n\")\n",
    "    print(metrics.classification_report(target_pred, target_test))\n",
    "    print(\"____________________________________________________________________________________________\", \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation on SVM Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='poly',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False) \n",
      "\n",
      "CV Score: [ 0.74285714  0.71153846  0.7         0.80555556  0.64705882] \n",
      "\n",
      "Mean CV Score: 0.721401996696 \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.72      0.79      0.75       167\n",
      "        1.0       0.73      0.64      0.68       145\n",
      "\n",
      "avg / total       0.72      0.72      0.72       312\n",
      "\n",
      "____________________________________________________________________________________________ \n",
      "\n",
      "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False) \n",
      "\n",
      "CV Score: [ 0.77419355  0.74418605  0.72916667  0.87096774  0.68888889] \n",
      "\n",
      "Mean CV Score: 0.761480578478 \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.83      0.78      0.80       196\n",
      "        1.0       0.66      0.72      0.69       116\n",
      "\n",
      "avg / total       0.76      0.76      0.76       312\n",
      "\n",
      "____________________________________________________________________________________________ \n",
      "\n",
      "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False) \n",
      "\n",
      "CV Score: [ 0.77419355  0.74418605  0.72916667  0.87096774  0.68888889] \n",
      "\n",
      "Mean CV Score: 0.761480578478 \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.83      0.78      0.80       196\n",
      "        1.0       0.66      0.72      0.69       116\n",
      "\n",
      "avg / total       0.76      0.76      0.76       312\n",
      "\n",
      "____________________________________________________________________________________________ \n",
      "\n",
      "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='sigmoid',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False) \n",
      "\n",
      "CV Score: [ 0.77419355  0.74418605  0.72916667  0.87096774  0.68888889] \n",
      "\n",
      "Mean CV Score: 0.761480578478 \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.83      0.78      0.80       196\n",
      "        1.0       0.66      0.72      0.69       116\n",
      "\n",
      "avg / total       0.76      0.76      0.76       312\n",
      "\n",
      "____________________________________________________________________________________________ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in svm_models:\n",
    "    model.fit(X_train, target_train)\n",
    "    target_pred = model.predict(X_test)\n",
    "    cv_score = cross_val_score(model, X_train, target_train, cv=5, scoring = 'precision')\n",
    "    print(model, \"\\n\")\n",
    "    print(\"CV Score:\",cv_score, \"\\n\")\n",
    "    print('Mean CV Score:',np.mean(cv_score), \"\\n\")\n",
    "    print(metrics.classification_report(target_pred, target_test))\n",
    "    print(\"____________________________________________________________________________________________\", \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Accuracy Look: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### SVM Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.12 % Accuracy\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='poly',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False) \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.72      0.79      0.75       167\n",
      "        1.0       0.73      0.64      0.68       145\n",
      "\n",
      "avg / total       0.72      0.72      0.72       312\n",
      " \n",
      "\n",
      "____________________________________________________________________________________________ \n",
      "\n",
      "75.64 % Accuracy\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False) \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.83      0.78      0.80       196\n",
      "        1.0       0.66      0.72      0.69       116\n",
      "\n",
      "avg / total       0.76      0.76      0.76       312\n",
      " \n",
      "\n",
      "____________________________________________________________________________________________ \n",
      "\n",
      "75.64 % Accuracy\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False) \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.83      0.78      0.80       196\n",
      "        1.0       0.66      0.72      0.69       116\n",
      "\n",
      "avg / total       0.76      0.76      0.76       312\n",
      " \n",
      "\n",
      "____________________________________________________________________________________________ \n",
      "\n",
      "75.64 % Accuracy\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='sigmoid',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False) \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.83      0.78      0.80       196\n",
      "        1.0       0.66      0.72      0.69       116\n",
      "\n",
      "avg / total       0.76      0.76      0.76       312\n",
      " \n",
      "\n",
      "____________________________________________________________________________________________ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_kernels = ['poly','rbf','linear','sigmoid']\n",
    "for i in svm_kernels:\n",
    "    mod = svm.SVC(kernel = i)\n",
    "    mod.fit(X_train, target_train)\n",
    "    target_pred = mod.predict(X_test)\n",
    "    print(round(accuracy(target_test, target_pred)*100, 2), \"% Accuracy\")\n",
    "    print(mod, \"\\n\")\n",
    "    print(metrics.classification_report(target_pred, target_test), \"\\n\")\n",
    "    print(\"____________________________________________________________________________________________\", \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### All Other Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76.6 % Accuracy\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False) \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.86      0.77      0.81       205\n",
      "        1.0       0.63      0.76      0.69       107\n",
      "\n",
      "avg / total       0.78      0.77      0.77       312\n",
      "\n",
      "____________________________________________________________________________________________ \n",
      "\n",
      "75.96 % Accuracy\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False) \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.84      0.77      0.81       201\n",
      "        1.0       0.64      0.74      0.69       111\n",
      "\n",
      "avg / total       0.77      0.76      0.76       312\n",
      "\n",
      "____________________________________________________________________________________________ \n",
      "\n",
      "78.21 % Accuracy\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform') \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.88      0.78      0.83       206\n",
      "        1.0       0.65      0.78      0.71       106\n",
      "\n",
      "avg / total       0.80      0.78      0.79       312\n",
      "\n",
      "____________________________________________________________________________________________ \n",
      "\n",
      "73.72 % Accuracy\n",
      "GaussianNB(priors=None) \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.78      0.77      0.78       186\n",
      "        1.0       0.67      0.68      0.68       126\n",
      "\n",
      "avg / total       0.74      0.74      0.74       312\n",
      "\n",
      "____________________________________________________________________________________________ \n",
      "\n",
      "61.54 % Accuracy\n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True) \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      0.61      0.74       280\n",
      "        1.0       0.16      0.62      0.25        32\n",
      "\n",
      "avg / total       0.85      0.62      0.69       312\n",
      "\n",
      "____________________________________________________________________________________________ \n",
      "\n",
      "75.32 % Accuracy\n",
      "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True) \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.82      0.78      0.80       193\n",
      "        1.0       0.66      0.71      0.69       119\n",
      "\n",
      "avg / total       0.76      0.75      0.75       312\n",
      "\n",
      "____________________________________________________________________________________________ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in models: \n",
    "    model.fit(X_train, target_train)\n",
    "    target_pred = model.predict(X_test)\n",
    "    print(round(accuracy(target_test, target_pred)*100, 2), \"% Accuracy\")\n",
    "    print(model, \"\\n\")\n",
    "    print(metrics.classification_report(target_pred, target_test))\n",
    "    print(\"____________________________________________________________________________________________\", \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interact SVM Models to Test Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.32 % Accuracy\n",
      "SVC(C=50, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=50, gamma=50, kernel='poly',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False) \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.82      0.78      0.80       193\n",
      "        1.0       0.66      0.71      0.69       119\n",
      "\n",
      "avg / total       0.76      0.75      0.75       312\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"SVM Model: poly\"\"\"\n",
    "from ipywidgets import interact\n",
    "ranges = [1,100,1]\n",
    "@interact(c_range = ranges, degree = ranges, gamma = ranges)\n",
    "def acc1(c_range, degree, gamma):\n",
    "    model = svm.SVC(kernel = 'poly', C = c_range, degree = degree, gamma = gamma)\n",
    "    model.fit(X_train, target_train)\n",
    "    print(round(accuracy(target_test, target_pred)*100, 2), \"% Accuracy\")\n",
    "    print(model, \"\\n\")\n",
    "    print(metrics.classification_report(target_pred, target_test), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.32 % Accuracy\n",
      "SVC(C=50, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=50, gamma=50, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False) \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.82      0.78      0.80       193\n",
      "        1.0       0.66      0.71      0.69       119\n",
      "\n",
      "avg / total       0.76      0.75      0.75       312\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"SVM Model: rbf\"\"\"\n",
    "from ipywidgets import interact\n",
    "ranges = [1,100,1]\n",
    "@interact(c_range = ranges, degree = ranges, gamma = ranges)\n",
    "def acc2(c_range, degree, gamma):\n",
    "    model = svm.SVC(kernel = 'rbf', C = c_range, degree = degree, gamma = gamma)\n",
    "    model.fit(X_train, target_train)\n",
    "    print(round(accuracy(target_test, target_pred)*100, 2), \"% Accuracy\")\n",
    "    print(model, \"\\n\")\n",
    "    print(metrics.classification_report(target_pred, target_test), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.32 % Accuracy\n",
      "SVC(C=50, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=50, gamma=50, kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False) \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.82      0.78      0.80       193\n",
      "        1.0       0.66      0.71      0.69       119\n",
      "\n",
      "avg / total       0.76      0.75      0.75       312\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"SVM Model: linear\"\"\"\n",
    "from ipywidgets import interact\n",
    "ranges = [1,100,1]\n",
    "@interact(c_range = ranges, degree = ranges, gamma = ranges)\n",
    "def acc3(c_range, degree, gamma):\n",
    "    model = svm.SVC(kernel = 'linear', C = c_range, degree = degree, gamma = gamma)\n",
    "    model.fit(X_train, target_train)\n",
    "    print(round(accuracy(target_test, target_pred)*100, 2), \"% Accuracy\")\n",
    "    print(model, \"\\n\")\n",
    "    print(metrics.classification_report(target_pred, target_test), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.32 % Accuracy\n",
      "SVC(C=50, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=50, gamma=50, kernel='sigmoid',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False) \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.82      0.78      0.80       193\n",
      "        1.0       0.66      0.71      0.69       119\n",
      "\n",
      "avg / total       0.76      0.75      0.75       312\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"SVM Model: sigmoid\"\"\"\n",
    "from ipywidgets import interact\n",
    "ranges = [1,100,1]\n",
    "@interact(c_range = ranges, degree = ranges, gamma = ranges)\n",
    "def acc4(c_range, degree, gamma):\n",
    "    model = svm.SVC(kernel = 'sigmoid', C = c_range, degree = degree, gamma = gamma)\n",
    "    model.fit(X_train, target_train)\n",
    "    print(round(accuracy(target_test, target_pred)*100, 2), \"% Accuracy\")\n",
    "    print(model, \"\\n\")\n",
    "    print(metrics.classification_report(target_pred, target_test), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.32 % Accuracy\n"
     ]
    }
   ],
   "source": [
    "\"\"\"K Nearest Neighbors\"\"\"\n",
    "from ipywidgets import interact\n",
    "@interact(neighbors = [1,100,1])\n",
    "def acc5(neighbors):\n",
    "    model = KNeighborsClassifier(n_neighbors = neighbors)\n",
    "    model.fit(X_train, target_train)\n",
    "    print(round(accuracy(target_test, target_pred)*100, 2), \"% Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.32 % Accuracy \n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=51,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=51, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Random Forest\"\"\"\n",
    "from ipywidgets import interact\n",
    "ranges = [2,100,1]\n",
    "@interact(n_estimators = ranges, min_samples_split = ranges)\n",
    "def acc5(n_estimators, min_samples_split):\n",
    "    model = RandomForestClassifier(n_estimators = n_estimators, min_samples_split = min_samples_split)\n",
    "    model.fit(X_train, target_train)\n",
    "    print(round(accuracy(target_test, target_pred)*100, 2), \"% Accuracy\", \"\\n\")\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Accuracy on a Single Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76.28 % Accuracy\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False) \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.84      0.78      0.81       200\n",
      "        1.0       0.65      0.74      0.69       112\n",
      "\n",
      "avg / total       0.77      0.76      0.77       312\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = m1\n",
    "model.fit(X_train, target_train)\n",
    "target_pred = model.predict(X_test)\n",
    "print (round(accuracy(target_test, target_pred)*100, 2), \"% Accuracy\")\n",
    "print(model, \"\\n\")\n",
    "print(metrics.classification_report(target_pred, target_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.808080808081\n",
      "{'n_neighbors': 12}\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=12, p=2,\n",
      "           weights='uniform')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kerrylam/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_search.py:747: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Get Parameters of a Model Using: Model().get_params()\"\"\"\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\"\"\"Specify a Range\"\"\"\n",
    "ranges = range(1,31)\n",
    "\"\"\"Set a Model's Parameter to the Ranges to Try in GridSearch Using a Dictionary\"\"\"\n",
    "param_grid = dict(n_neighbors = ranges)\n",
    "\"\"\"Specify the Model\"\"\"\n",
    "Model = KNeighborsClassifier()\n",
    "\"\"\"Instantiate the GridSearchModel With Model, Parameter Grid, and Proper Parameters of Grid\"\"\"\n",
    "grid = GridSearchCV(Model, param_grid, cv = 10, scoring = 'accuracy')\n",
    "\"\"\"Fit Unsplit Data\"\"\"\n",
    "grid.fit(X, target)\n",
    "\"\"\"Output Scores\"\"\"\n",
    "grid.grid_scores_\n",
    "\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search On SVM Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.786756453423\n",
      "{'kernel': 'rbf'}\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kerrylam/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_search.py:747: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "kernel_options = ['poly','rbf','linear','sigmoid']\n",
    "\"\"\"Specify a Range\"\"\"\n",
    "ranges = range(1,31)\n",
    "\"\"\"Set a Model's Parameter to the Ranges to Try in GridSearch Using a Dictionary\"\"\"\n",
    "param_grid = dict(kernel = kernel_options)\n",
    "\"\"\"Specify the Model\"\"\"\n",
    "Model = svm.SVC()\n",
    "\"\"\"Instantiate the GridSearchModel With Model, Parameter Grid, and Proper Parameters of Grid\"\"\"\n",
    "grid = GridSearchCV(Model, param_grid, cv = 10, scoring = 'accuracy')\n",
    "\"\"\"Fit Unsplit Data\"\"\"\n",
    "grid.fit(X, target)\n",
    "\"\"\"Output Scores\"\"\"\n",
    "grid.grid_scores_\n",
    "\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on Actual Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>897</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>898</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>899</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>901</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>903</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>905</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>906</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>907</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>908</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>909</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>910</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>911</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>912</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>913</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>914</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>915</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>916</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>917</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>918</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>919</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>920</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>921</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>1280</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>1281</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>1282</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>1283</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>1284</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>1285</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>1286</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>1287</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>1288</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>1289</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>1290</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>1291</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>1292</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>1293</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>1294</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>1295</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>1296</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>1297</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>1298</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>1299</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>1300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>1301</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>1302</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>1303</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>1304</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0            892         0\n",
       "1            893         1\n",
       "2            894         0\n",
       "3            895         0\n",
       "4            896         0\n",
       "5            897         0\n",
       "6            898         0\n",
       "7            899         0\n",
       "8            900         1\n",
       "9            901         0\n",
       "10           902         0\n",
       "11           903         0\n",
       "12           904         1\n",
       "13           905         0\n",
       "14           906         1\n",
       "15           907         1\n",
       "16           908         0\n",
       "17           909         0\n",
       "18           910         0\n",
       "19           911         0\n",
       "20           912         1\n",
       "21           913         0\n",
       "22           914         1\n",
       "23           915         1\n",
       "24           916         1\n",
       "25           917         0\n",
       "26           918         1\n",
       "27           919         0\n",
       "28           920         0\n",
       "29           921         0\n",
       "..           ...       ...\n",
       "388         1280         0\n",
       "389         1281         0\n",
       "390         1282         0\n",
       "391         1283         1\n",
       "392         1284         0\n",
       "393         1285         0\n",
       "394         1286         0\n",
       "395         1287         1\n",
       "396         1288         0\n",
       "397         1289         1\n",
       "398         1290         0\n",
       "399         1291         0\n",
       "400         1292         1\n",
       "401         1293         0\n",
       "402         1294         1\n",
       "403         1295         0\n",
       "404         1296         0\n",
       "405         1297         0\n",
       "406         1298         0\n",
       "407         1299         0\n",
       "408         1300         1\n",
       "409         1301         1\n",
       "410         1302         1\n",
       "411         1303         1\n",
       "412         1304         0\n",
       "413         1305         0\n",
       "414         1306         1\n",
       "415         1307         0\n",
       "416         1308         0\n",
       "417         1309         0\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: Update Parameters For Better Accuracy\n",
    "estimator = m1\n",
    "y_pred = estimator.predict(test)\n",
    "predictions = pd.DataFrame(ID)\n",
    "def predict(predictions):\n",
    "    predictions[\"Survived\"] = y_pred\n",
    "    predictions = predictions.astype(int)\n",
    "    return predictions\n",
    "\n",
    "predict(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predictions.to_csv('titanic_submission.csv',index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "widgets": {
   "state": {
    "3e5870879ad94bd0b6727a1a462ba5a5": {
     "views": [
      {
       "cell_index": 44
      }
     ]
    },
    "418a68cc97bc48bb9c706b96a267d556": {
     "views": [
      {
       "cell_index": 42
      }
     ]
    },
    "795bc0b92e8a45bfb01088458aac3139": {
     "views": [
      {
       "cell_index": 41
      }
     ]
    },
    "985f5dda4b9a4cc6a158665e849738bd": {
     "views": [
      {
       "cell_index": 39
      }
     ]
    },
    "b74b14d0ce9149169e35b36b8bb58ce2": {
     "views": [
      {
       "cell_index": 43
      }
     ]
    },
    "b77268d8dd374fe6bfaa7d388547a380": {
     "views": [
      {
       "cell_index": 40
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
